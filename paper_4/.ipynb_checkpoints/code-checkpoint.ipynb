{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1623bbe9",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__BroadcastTo_device_/job:localhost/replica:0/task:0/device:GPU:0}} Incompatible shapes: [1024,1024] vs. [64,16,1024] [Op:BroadcastTo]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 94\u001b[0m\n\u001b[1;32m     91\u001b[0m dec_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims([\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m batch_size, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Run decoder\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m dec_output, dec_hidden, attention_weights \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Output shapes\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoder output shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, enc_output\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# (batch_size, seq_len, units)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 62\u001b[0m, in \u001b[0;36mdecoder\u001b[0;34m(dec_input, dec_hidden, enc_output, vocab_size, embedding_dim, units)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecoder\u001b[39m(dec_input, dec_hidden, enc_output, vocab_size, embedding_dim, units):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Perform attention mechanism\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     context_vector, attention_weights \u001b[38;5;241m=\u001b[39m \u001b[43mbahdanau_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Embedding for decoder input\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     dec_embedding \u001b[38;5;241m=\u001b[39m Embedding(vocab_size, embedding_dim)(dec_input)\n",
      "Cell \u001b[0;32mIn[9], line 45\u001b[0m, in \u001b[0;36mbahdanau_attention\u001b[0;34m(query, values, units)\u001b[0m\n\u001b[1;32m     42\u001b[0m W2_query \u001b[38;5;241m=\u001b[39m W2(query_with_time_axis)  \u001b[38;5;66;03m# shape (batch_size, 1, units)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Broadcast W2_query across the time steps to match W1_values shape\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m W2_query \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW2_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW1_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape (batch_size, max_length, units)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Compute the score by adding W1_values and W2_query, then applying tanh\u001b[39;00m\n\u001b[1;32m     48\u001b[0m score \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mtanh(W1_values \u001b[38;5;241m+\u001b[39m W2_query)  \u001b[38;5;66;03m# shape (batch_size, max_length, units)\u001b[39;00m\n",
      "File \u001b[0;32m~/tensorflow/lib/python3.11/site-packages/tensorflow/python/ops/gen_array_ops.py:891\u001b[0m, in \u001b[0;36mbroadcast_to\u001b[0;34m(input, shape, name)\u001b[0m\n\u001b[1;32m    889\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m--> 891\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbroadcast_to_eager_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_SymbolicException:\n\u001b[1;32m    894\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[0;32m~/tensorflow/lib/python3.11/site-packages/tensorflow/python/ops/gen_array_ops.py:937\u001b[0m, in \u001b[0;36mbroadcast_to_eager_fallback\u001b[0;34m(input, shape, name, ctx)\u001b[0m\n\u001b[1;32m    935\u001b[0m _inputs_flat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28minput\u001b[39m, shape]\n\u001b[1;32m    936\u001b[0m _attrs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_T, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTidx\u001b[39m\u001b[38;5;124m\"\u001b[39m, _attr_Tidx)\n\u001b[0;32m--> 937\u001b[0m _result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBroadcastTo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_inputs_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n\u001b[1;32m    940\u001b[0m   _execute\u001b[38;5;241m.\u001b[39mrecord_gradient(\n\u001b[1;32m    941\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBroadcastTo\u001b[39m\u001b[38;5;124m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[0;32m~/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__BroadcastTo_device_/job:localhost/replica:0/task:0/device:GPU:0}} Incompatible shapes: [1024,1024] vs. [64,16,1024] [Op:BroadcastTo]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Concatenate\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_size = 10000  # Example vocab size, adjust based on your data\n",
    "batch_size = 64\n",
    "max_seq_len = 16\n",
    "\n",
    "# Initialize hidden state\n",
    "def initialize_hidden_state(batch_sz, units):\n",
    "    return tf.zeros((batch_sz, units))\n",
    "\n",
    "# Encoder\n",
    "def encoder(input_sequence, vocab_size, embedding_dim, units):\n",
    "    embedding = Embedding(vocab_size, embedding_dim)(input_sequence)\n",
    "    \n",
    "    # The GRU layer returns multiple values when return_state=True\n",
    "    gru_output = GRU(units, return_sequences=True, return_state=True,\n",
    "                     recurrent_initializer='glorot_uniform')(embedding)\n",
    "\n",
    "    # Extract only the first two values: sequence output and final hidden state\n",
    "    gru_output, *gru_hidden = gru_output\n",
    "\n",
    "    return gru_output, gru_hidden[0]  # Return the sequence and the first hidden state\n",
    "\n",
    "# Fixed Bahdanau Attention Mechanism\n",
    "def bahdanau_attention(query, values, units):\n",
    "    # query: decoder hidden state, shape: (batch_size, hidden_size)\n",
    "    # values: encoder output, shape: (batch_size, max_length, hidden_size)\n",
    "\n",
    "    # Dense layers for attention\n",
    "    W1 = Dense(units)\n",
    "    W2 = Dense(units)\n",
    "    V = Dense(1)\n",
    "\n",
    "    # Add time axis to query for broadcasting\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)  # shape (batch_size, 1, hidden_size)\n",
    "\n",
    "    # Compute W1_values (encoder output) and W2_query (decoder hidden state)\n",
    "    W1_values = W1(values)  # shape (batch_size, max_length, units)\n",
    "    W2_query = W2(query_with_time_axis)  # shape (batch_size, 1, units)\n",
    "\n",
    "    # Ensure W2_query has shape (batch_size, max_length, units) for broadcasting\n",
    "    W2_query = tf.broadcast_to(W2_query, W1_values.shape)  # shape (batch_size, max_length, units)\n",
    "\n",
    "    # Compute the score by adding W1_values and W2_query, then applying tanh\n",
    "    score = tf.nn.tanh(W1_values + W2_query)  # shape (batch_size, max_length, units)\n",
    "\n",
    "    # Compute attention weights\n",
    "    attention_weights = tf.nn.softmax(V(score), axis=1)  # shape (batch_size, max_length, 1)\n",
    "\n",
    "    # Compute context vector as the weighted sum of the encoder's output\n",
    "    context_vector = attention_weights * values  # shape (batch_size, max_length, hidden_size)\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)  # shape (batch_size, hidden_size)\n",
    "\n",
    "    return context_vector, attention_weights\n",
    "\n",
    "# Decoder\n",
    "def decoder(dec_input, dec_hidden, enc_output, vocab_size, embedding_dim, units):\n",
    "    # Perform attention mechanism\n",
    "    context_vector, attention_weights = bahdanau_attention(dec_hidden, enc_output, units)\n",
    "\n",
    "    # Embedding for decoder input\n",
    "    dec_embedding = Embedding(vocab_size, embedding_dim)(dec_input)\n",
    "\n",
    "    # Concatenate context vector with decoder input embedding\n",
    "    dec_input_concat = Concatenate(axis=-1)([tf.expand_dims(context_vector, 1), dec_embedding])\n",
    "\n",
    "    # Pass through GRU\n",
    "    gru_output, gru_state = GRU(units, return_sequences=True, return_state=True,\n",
    "                                recurrent_initializer='glorot_uniform')(dec_input_concat)\n",
    "\n",
    "    # Dense layer to generate predictions\n",
    "    output = Dense(vocab_size)(tf.reshape(gru_output, (-1, gru_output.shape[2])))\n",
    "\n",
    "    return output, gru_state, attention_weights\n",
    "\n",
    "# Example usage\n",
    "# Input sample for encoder and decoder\n",
    "sample_input = tf.random.uniform((batch_size, max_seq_len), dtype=tf.int32, minval=0, maxval=vocab_size)\n",
    "sample_target = tf.random.uniform((batch_size, 1), dtype=tf.int32, minval=0, maxval=vocab_size)\n",
    "\n",
    "# Initialize hidden state for encoder\n",
    "enc_hidden = initialize_hidden_state(batch_size, units)\n",
    "\n",
    "# Run encoder\n",
    "enc_output, enc_hidden = encoder(sample_input, vocab_size, embedding_dim, units)\n",
    "\n",
    "# Decoder's initial input (usually start token <start>)\n",
    "dec_input = tf.expand_dims([0] * batch_size, 1)\n",
    "\n",
    "# Run decoder\n",
    "dec_output, dec_hidden, attention_weights = decoder(dec_input, enc_hidden, enc_output, vocab_size, embedding_dim, units)\n",
    "\n",
    "# Output shapes\n",
    "print(\"Encoder output shape:\", enc_output.shape)  # (batch_size, seq_len, units)\n",
    "print(\"Encoder hidden state shape:\", enc_hidden.shape)  # (batch_size, units)\n",
    "print(\"Decoder output shape:\", dec_output.shape)  # (batch_size * seq_len, vocab_size)\n",
    "print(\"Attention weights shape:\", attention_weights.shape)  # (batch_size, seq_len, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6415e12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
