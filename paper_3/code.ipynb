{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e923d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Hyperparameters\n",
    "embedding_dim = 300  # Embedding dimensions\n",
    "hidden_units = 512  # Hidden units for GRU\n",
    "vocab_size = 10000  # Size of the vocabulary\n",
    "max_sentence_length = 50  # Maximum length of a sentence\n",
    "\n",
    "# Encoder\n",
    "class SkipThoughtEncoder(Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_units):\n",
    "        super(SkipThoughtEncoder, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        self.bidirectional_gru = Bidirectional(GRU(hidden_units, return_sequences=False))\n",
    "\n",
    "    def call(self, input_sentence):\n",
    "        embedded_sentence = self.embedding(input_sentence)\n",
    "        sentence_vector = self.bidirectional_gru(embedded_sentence)\n",
    "        return sentence_vector\n",
    "\n",
    "# Decoder\n",
    "class SkipThoughtDecoder(Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_units):\n",
    "        super(SkipThoughtDecoder, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = GRU(hidden_units, return_sequences=True, return_state=True)\n",
    "        self.dense = Dense(vocab_size)\n",
    "\n",
    "    def call(self, input_sentence, initial_state):\n",
    "        embedded_sentence = self.embedding(input_sentence)\n",
    "        output, state = self.gru(embedded_sentence, initial_state=initial_state)\n",
    "        logits = self.dense(output)\n",
    "        return logits, state\n",
    "\n",
    "# Build the Skip-Thought model\n",
    "class SkipThoughtModel(Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_units):\n",
    "        super(SkipThoughtModel, self).__init__()\n",
    "        self.encoder = SkipThoughtEncoder(vocab_size, embedding_dim, hidden_units)\n",
    "        self.decoder_prev = SkipThoughtDecoder(vocab_size, embedding_dim, hidden_units)\n",
    "        self.decoder_next = SkipThoughtDecoder(vocab_size, embedding_dim, hidden_units)\n",
    "\n",
    "    def call(self, input_sentence, target_prev_sentence, target_next_sentence):\n",
    "        sentence_vector = self.encoder(input_sentence)\n",
    "        logits_prev, _ = self.decoder_prev(target_prev_sentence, sentence_vector)\n",
    "        logits_next, _ = self.decoder_next(target_next_sentence, sentence_vector)\n",
    "        return logits_prev, logits_next\n",
    "\n",
    "model = SkipThoughtModel(vocab_size=vocab_size, embedding_dim=embedding_dim, hidden_units=hidden_units)\n",
    "\n",
    "# Input tensors\n",
    "input_sentence = tf.random.uniform((32, max_sentence_length), minval=0, maxval=vocab_size, dtype=tf.int32)  # batch_size=32\n",
    "target_prev_sentence = tf.random.uniform((32, max_sentence_length), minval=0, maxval=vocab_size, dtype=tf.int32)\n",
    "target_next_sentence = tf.random.uniform((32, max_sentence_length), minval=0, maxval=vocab_size, dtype=tf.int32)\n",
    "\n",
    "# Forward pass\n",
    "logits_prev, logits_next = model(input_sentence, target_prev_sentence, target_next_sentence)\n",
    "\n",
    "# Print shapes\n",
    "print(\"Logits for previous sentence prediction:\", logits_prev.shape)\n",
    "print(\"Logits for next sentence prediction:\", logits_next.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
